#!/usr/bin/env python3
"""
Blog Image Generator using Imagen 3
ãƒ–ãƒ­ã‚°è¨˜äº‹ã®ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒãƒ»ã‚µãƒ ãƒã‚¤ãƒ«ç”»åƒã‚’Imagen 3ã§è‡ªå‹•ç”Ÿæˆ

Usage:
    python image_generator.py --outline path/to/outline.md --mode eyecatch
    python image_generator.py --outline path/to/outline.md --mode thumbnail --chapter 1
    python image_generator.py --outline path/to/outline.md --mode all
"""

import os
import sys
import argparse
import json
import re
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, List
from io import BytesIO

from google import genai
from google.genai import types
from openai import OpenAI
from PIL import Image, ImageFilter, ImageDraw
from dotenv import load_dotenv
import base64
import numpy as np

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from utils.output_manager import OutputManager

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

class BlogImageGenerator:
    def __init__(self):
        """åˆæœŸåŒ–"""
        # Google Gemini API (ã‚µãƒ ãƒã‚¤ãƒ«ç”¨)
        self.google_api_key = os.getenv('GOOGLE_API_KEY')
        if not self.google_api_key:
            raise ValueError("GOOGLE_API_KEY not found in .env file")
        
        # OpenAI API (ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒç”¨)
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        if not self.openai_api_key:
            raise ValueError("OPENAI_API_KEY not found in .env file")
        
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        self.google_client = genai.Client(api_key=self.google_api_key)
        self.openai_client = OpenAI(api_key=self.openai_api_key)
        
        self.imagen_model = 'imagen-3.0-generate-002'
        self.openai_image_model = 'gpt-image-1'
        
        # å‡ºåŠ›ç®¡ç†ã‚¯ãƒ©ã‚¹åˆæœŸåŒ–
        self.output_manager = OutputManager()
        
        # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚
        self.outputs_dir = Path('outputs')
        self.outputs_dir.mkdir(exist_ok=True)
        
    def load_outline(self, outline_path: str) -> Dict:
        """ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open(outline_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰IDã¨ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æŠ½å‡º
            filename = Path(outline_path).stem
            match = re.search(r'(\d{8}_\d{6})_outline_(.+)', filename)
            if match:
                timestamp = match.group(1)
                outline_id = match.group(2)
            else:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                outline_id = 'unknown'
            
            return {
                'content': content,
                'timestamp': timestamp,
                'outline_id': outline_id,
                'filename': filename
            }
        except Exception as e:
            print(f"Error loading outline: {e}")
            return None
    
    def extract_chapters(self, outline_content: str) -> List[str]:
        """ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã‹ã‚‰ç« ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º"""
        chapters = []
        lines = outline_content.split('\n')
        
        for line in lines:
            # Blog Outline (TOC)ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰ç« ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º
            if re.match(r'^\d+\.\s+', line.strip()):
                chapter_title = re.sub(r'^\d+\.\s+', '', line.strip())
                chapters.append(chapter_title)
        
        return chapters
    
    def generate_prompt_with_gemini(self, template_file: str, outline_data: Dict, target_chapter: Optional[str] = None) -> str:
        """Geminiã‚’ä½¿ã£ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰ç”»åƒç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ"""
        try:
            with open(template_file, 'r', encoding='utf-8') as f:
                template = f.read()
            
            # å¤‰æ•°ç½®æ›
            content = template.replace('{{outline}}', outline_data['content'])
            if target_chapter:
                content = content.replace('{{target_h2}}', target_chapter)
                # ç« ç•ªå·ã‚’æŠ½å‡º
                chapter_match = re.search(r'^(\d+)\.', target_chapter)
                chapter_number = chapter_match.group(1) if chapter_match else '1'
                content = content.replace('{{chapter_number}}', chapter_number)
            
            # Gemini Text APIã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚’å®Ÿè¡Œ
            try:
                response = self.google_client.models.generate_content(
                    model='gemini-2.0-flash-exp',
                    contents=content
                )
                return response.text
            except Exception as e:
                print(f"Warning: Gemini text generation failed: {e}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãã®ã¾ã¾ä½¿ç”¨
                return content
            
        except Exception as e:
            print(f"Error generating prompt: {e}")
            return None
    
    def extract_yaml_and_convert_to_prompt(self, generated_text: str) -> str:
        """ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰YAMLè¨­å®šã‚’æŠ½å‡ºã—ã¦Imagen 3ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¤‰æ›"""
        try:
            # YAMLéƒ¨åˆ†ã‚’æŠ½å‡º
            yaml_start = generated_text.find('```yaml')
            yaml_end = generated_text.find('```', yaml_start + 7)
            
            if yaml_start != -1 and yaml_end != -1:
                yaml_content = generated_text[yaml_start + 7:yaml_end].strip()
                return self.yaml_to_imagen_prompt(yaml_content)
            else:
                # YAMLãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å¾“æ¥ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŠ½å‡ºã‚’è©¦è¡Œ
                return self.extract_legacy_prompt(generated_text)
                
        except Exception as e:
            print(f"YAML processing failed, using fallback: {e}")
            return self.extract_legacy_prompt(generated_text)
    
    def yaml_to_imagen_prompt(self, yaml_content: str) -> str:
        """YAMLè¨­å®šã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¤‰æ›ï¼ˆOpenAI/Imagenå¯¾å¿œï¼‰"""
        # YAMLå†…ã®è¨­å®šå€¤ã‚’æŠ½å‡º
        style_match = re.search(r'style:\s*"([^"]+)"', yaml_content)
        theme_color_match = re.search(r'theme_color:\s*"([^"]+)"', yaml_content)
        mood_match = re.search(r'mood:\s*"([^"]+)"', yaml_content)
        background_type_match = re.search(r'type:\s*"([^"]+)"', yaml_content)
        background_color_match = re.search(r'color:\s*"([^"]+)"', yaml_content)
        
        # ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒã‹ã‚µãƒ ãƒã‚¤ãƒ«ã‹ã‚’åˆ¤å®š
        is_eyecatch = "text_support: true" in yaml_content or "main_title" in yaml_content
        
        if is_eyecatch:
            # ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒç”¨ï¼ˆOpenAI gpt-image-1ã§æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œï¼‰
            main_text_matches = re.findall(r'content:\s*"([^"]+)"', yaml_content)
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ï¼ˆã‚µãƒ ãƒã‚¤ãƒ«é¢¨ã®ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ã‚¹ã‚¿ã‚¤ãƒ« + æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆï¼‰
            prompt_parts = []
            
            # ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆã‚µãƒ ãƒã‚¤ãƒ«é¢¨ï¼‰
            prompt_parts.append("Creative digital illustration")
            prompt_parts.append("featuring professional business person or educator")
            prompt_parts.append("in modern tech environment or classroom setting")
            prompt_parts.append("with futuristic elements and digital effects")
            
            # æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆ
            if main_text_matches:
                main_text = main_text_matches[0]
                prompt_parts.append(f"prominent Japanese text '{main_text}' displayed clearly")
                prompt_parts.append("professional typography with bold modern font")
            
            # ã‚¹ã‚¿ã‚¤ãƒ«ã¨è‰²å½©ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ï¼‰
            if style_match:
                style = style_match.group(1)
                prompt_parts.append(f"artistic style: {style}")
            
            if theme_color_match:
                colors = theme_color_match.group(1)
                prompt_parts.append(f"color scheme: {colors}")
            else:
                prompt_parts.append("vibrant blue and orange color palette")
            
            # ç’°å¢ƒè¨­å®š
            if background_type_match:
                bg_type = background_type_match.group(1)
                prompt_parts.append(f"background: {bg_type}")
            else:
                prompt_parts.append("modern office or educational environment")
            
            # é›°å›²æ°—
            if mood_match:
                mood = mood_match.group(1)
                prompt_parts.append(f"mood: {mood}")
            else:
                prompt_parts.append("professional and engaging atmosphere")
            
            # å“è³ªè¨­å®š
            prompt_parts.extend([
                "high quality digital art",
                "engaging visual composition",
                "modern and attractive design",
                "professional presentation style"
            ])
        
        else:
            # ã‚µãƒ ãƒã‚¤ãƒ«ç”¨ï¼ˆImagen 3ã§ãƒ†ã‚­ã‚¹ãƒˆãªã—ï¼‰
            character_matches = re.findall(r'character_illustration[^}]*content:\s*"([^"]+)"', yaml_content)
            environment_matches = re.findall(r'contextual_background[^}]*content:\s*"([^"]+)"', yaml_content)
            dynamic_matches = re.findall(r'dynamic_objects[^}]*content:\s*"([^"]+)"', yaml_content)
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
            prompt_parts = []
            
            # ã‚¹ã‚¿ã‚¤ãƒ«
            if style_match:
                style = style_match.group(1)
                prompt_parts.append(f"Creative illustration, {style.lower()}")
            else:
                prompt_parts.append("Creative digital illustration")
            
            # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¦ç´ 
            if character_matches:
                character_desc = character_matches[0]
                prompt_parts.append(f"featuring {character_desc}")
            
            # ç’°å¢ƒãƒ»èƒŒæ™¯
            if environment_matches:
                env_desc = environment_matches[0]
                prompt_parts.append(f"in {env_desc}")
            elif background_type_match:
                bg_type = background_type_match.group(1)
                prompt_parts.append(f"environment: {bg_type}")
            
            # ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯è¦ç´ 
            if dynamic_matches:
                dynamic_desc = dynamic_matches[0]
                prompt_parts.append(f"with {dynamic_desc}")
            
            # è‰²å½©
            if theme_color_match:
                colors = theme_color_match.group(1)
                prompt_parts.append(f"color palette: {colors}")
            
            # é›°å›²æ°—
            if mood_match:
                mood = mood_match.group(1)
                prompt_parts.append(f"atmosphere: {mood}")
            
            # åŸºæœ¬è¨­å®šï¼ˆãƒ†ã‚­ã‚¹ãƒˆæ˜ç¢ºé™¤å¤–ï¼‰
            prompt_parts.extend([
                "no text, no letters, no words",
                "pure visual storytelling",
                "16:9 aspect ratio",
                "high quality digital art",
                "detailed and immersive"
            ])
        
        final_prompt = ", ".join(prompt_parts)
        
        # é•·ã•åˆ¶é™
        if len(final_prompt) > 400:
            important_parts = final_prompt.split(", ")[:8]  # é‡è¦ãªéƒ¨åˆ†ã‚’ä¿æŒ
            final_prompt = ", ".join(important_parts)
        
        return final_prompt
    
    def extract_legacy_prompt(self, generated_text: str) -> str:
        """å¾“æ¥ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŠ½å‡ºæ–¹æ³•ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        # DALL-E 3 Prompt: ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã™
        lines = generated_text.split('\n')
        prompt_lines = []
        in_prompt_section = False
        
        for line in lines:
            if 'DALL-E 3 Prompt:' in line or 'Prompt:' in line:
                in_prompt_section = True
                continue
            elif line.startswith('```') and in_prompt_section:
                if prompt_lines:  # æ—¢ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’åé›†æ¸ˆã¿ãªã‚‰çµ‚äº†
                    break
                continue
            elif in_prompt_section and line.strip():
                if not line.startswith('**') and not line.startswith('#') and not line.startswith('-'):
                    prompt_lines.append(line.strip())
        
        extracted_prompt = ' '.join(prompt_lines) if prompt_lines else generated_text
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æœ€é©åŒ–ï¼ˆçŸ­ãç°¡æ½”ã«ï¼‰
        if len(extracted_prompt) > 300:
            # ã‚ˆã‚Šå³æ ¼ã«çŸ­ç¸®
            important_parts = []
            for line in extracted_prompt.split('.'):
                line = line.strip()
                if line and any(keyword in line.lower() for keyword in ['style', 'professional', 'modern', 'clean', 'colors', 'blue']):
                    important_parts.append(line)
            
            if important_parts:
                extracted_prompt = '. '.join(important_parts[:3]) + '.'
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€åˆã®200æ–‡å­—ã®ã¿
                extracted_prompt = extracted_prompt[:200].split('.')[0] + '.'
        
        return extracted_prompt
    
    def generate_image_openai(self, prompt: str) -> Optional[bytes]:
        """OpenAI gpt-image-1ã§ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒç”»åƒç”Ÿæˆï¼ˆæ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œï¼‰"""
        try:
            print(f"ğŸ¨ Generating eyecatch with OpenAI: {prompt[:100]}...")
            
            response = self.openai_client.images.generate(
                model=self.openai_image_model,
                prompt=prompt,
                size="1536x1024",  # gpt-image-1ã®æ¨ªé•·ã‚µã‚¤ã‚º
                quality="high",
                n=1
            )
            
            # base64ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆgpt-image-1ã¯base64ã‚’è¿”ã™ï¼‰
            if response.data and len(response.data) > 0:
                image_base64 = response.data[0].b64_json
                return base64.b64decode(image_base64)
            else:
                print("No images generated by OpenAI")
                return None
                
        except Exception as e:
            print(f"Error generating image with OpenAI: {e}")
            return None
    
    def generate_image_imagen(self, prompt: str) -> Optional[bytes]:
        """Imagen 3ã§ã‚µãƒ ãƒã‚¤ãƒ«ç”»åƒç”Ÿæˆï¼ˆãƒ†ã‚­ã‚¹ãƒˆãªã—ï¼‰"""
        try:
            print(f"ğŸ¨ Generating thumbnail with Imagen 3: {prompt[:100]}...")
            
            response = self.google_client.models.generate_images(
                model=self.imagen_model,
                prompt=prompt,
                config=types.GenerateImagesConfig(
                    number_of_images=1,
                    aspect_ratio="16:9",  # ãƒ–ãƒ­ã‚°ç”¨ã®æ¯”ç‡
                    safety_filter_level="block_low_and_above",
                    person_generation="allow_adult"
                )
            )
            
            # æœ€åˆã®ç”»åƒã‚’å–å¾—
            if response.generated_images:
                generated_image = response.generated_images[0]
                return generated_image.image.image_bytes
            else:
                print("No images generated by Imagen 3")
                return None
                
        except Exception as e:
            print(f"Error generating image with Imagen 3: {e}")
            return None
    
    def extend_image_to_16_9(self, image: Image.Image) -> Image.Image:
        """1536Ã—1024ã®ç”»åƒã‚’16:9ï¼ˆ1920Ã—1080ï¼‰ã«æ‹¡å¼µï¼ˆãƒ–ãƒ©ãƒ¼å»¶é•·ï¼‰"""
        try:
            # ç¾åœ¨ã®ã‚µã‚¤ã‚ºã¨ç›®æ¨™ã‚µã‚¤ã‚º
            current_width, current_height = image.size
            target_width, target_height = 1920, 1080
            
            print(f"ğŸ“ Extending image from {current_width}Ã—{current_height} to {target_width}Ã—{target_height}")
            
            # æ–°ã—ã„ã‚­ãƒ£ãƒ³ãƒã‚¹ä½œæˆ
            extended_image = Image.new('RGB', (target_width, target_height), (0, 0, 0))
            
            # å…ƒç”»åƒã‚’ä¸­å¤®ã«é…ç½®
            x_offset = (target_width - current_width) // 2
            y_offset = (target_height - current_height) // 2
            extended_image.paste(image, (x_offset, y_offset))
            
            # å·¦å³ã®æ‹¡å¼µï¼ˆãƒ–ãƒ©ãƒ¼ï¼‰
            if x_offset > 0:
                # å·¦ç«¯ã‚’æ‹¡å¼µ
                left_edge = image.crop((0, 0, 20, current_height))  # å·¦ç«¯20px
                left_blurred = left_edge.filter(ImageFilter.GaussianBlur(radius=3))
                left_stretched = left_blurred.resize((x_offset, current_height))
                extended_image.paste(left_stretched, (0, y_offset))
                
                # å³ç«¯ã‚’æ‹¡å¼µ
                right_edge = image.crop((current_width-20, 0, current_width, current_height))  # å³ç«¯20px
                right_blurred = right_edge.filter(ImageFilter.GaussianBlur(radius=3))
                right_stretched = right_blurred.resize((x_offset, current_height))
                extended_image.paste(right_stretched, (x_offset + current_width, y_offset))
            
            # ä¸Šä¸‹ã®æ‹¡å¼µï¼ˆãƒ–ãƒ©ãƒ¼ï¼‰
            if y_offset > 0:
                # ä¸Šç«¯ã‚’æ‹¡å¼µï¼ˆå…¨å¹…ã§ï¼‰
                top_edge = extended_image.crop((0, y_offset, target_width, y_offset + 20))  # ä¸Šç«¯20px
                top_blurred = top_edge.filter(ImageFilter.GaussianBlur(radius=5))
                top_stretched = top_blurred.resize((target_width, y_offset))
                extended_image.paste(top_stretched, (0, 0))
                
                # ä¸‹ç«¯ã‚’æ‹¡å¼µï¼ˆå…¨å¹…ã§ï¼‰
                bottom_edge = extended_image.crop((0, y_offset + current_height - 20, target_width, y_offset + current_height))  # ä¸‹ç«¯20px
                bottom_blurred = bottom_edge.filter(ImageFilter.GaussianBlur(radius=5))
                bottom_stretched = bottom_blurred.resize((target_width, y_offset))
                extended_image.paste(bottom_stretched, (0, y_offset + current_height))
            
            # è§’ã®éƒ¨åˆ†ã‚’ã•ã‚‰ã«ãƒ–ãƒ©ãƒ¼ã§è‡ªç„¶ã«
            extended_image = extended_image.filter(ImageFilter.GaussianBlur(radius=0.5))
            
            print("âœ… Image extended to 16:9 with blur padding")
            return extended_image
            
        except Exception as e:
            print(f"Warning: Image extension failed: {e}")
            return image  # å¤±æ•—æ™‚ã¯å…ƒç”»åƒã‚’è¿”ã™
    
    def save_image(self, image_data: bytes, filename: str, metadata: Optional[Dict] = None, file_type: str = 'image', chapter: Optional[int] = None) -> str:
        """ç”»åƒã‚’è‡ªå‹•åˆ†é¡ã—ã¦ä¿å­˜"""
        try:
            # ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’PILã§å‡¦ç†
            image = Image.open(BytesIO(image_data))
            original_size = image.size
            
            # ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒç”»åƒï¼ˆ1536Ã—1024ï¼‰ã®å ´åˆã¯16:9ã«æ‹¡å¼µ
            if original_size == (1536, 1024):
                print(f"ğŸ¨ Detected OpenAI eyecatch image, extending to 16:9...")
                image = self.extend_image_to_16_9(image)
            
            # Webæœ€é©åŒ–
            if image.size[0] > 1920:  # å¹…ãŒ1920pxã‚ˆã‚Šå¤§ãã„å ´åˆãƒªã‚µã‚¤ã‚º
                ratio = 1920 / image.size[0]
                new_size = (1920, int(image.size[1] * ratio))
                image = image.resize(new_size, Image.Resampling.LANCZOS)
            
            # ä¿å­˜å‡¦ç†
            if metadata:
                # æ–°ã—ã„è‡ªå‹•åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨
                from io import BytesIO
                img_bytes = BytesIO()
                image.save(img_bytes, 'PNG', optimize=True)
                img_bytes.seek(0)
                
                filepath = self.output_manager.save_binary(img_bytes.getvalue(), metadata, file_type, chapter)
            else:
                # å¾“æ¥ã®æ–¹æ³•ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
                filepath = self.outputs_dir / filename
                image.save(filepath, 'PNG', optimize=True)
                filepath = str(filepath)
            
            print(f"âœ… Image saved: {filepath} ({image.size[0]}x{image.size[1]})")
            return filepath
            
        except Exception as e:
            print(f"Error saving image: {e}")
            return None
    
    def generate_eyecatch(self, outline_data: Dict) -> Optional[str]:
        """ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒç”»åƒç”Ÿæˆï¼ˆOpenAI gpt-image-1ä½¿ç”¨ï¼‰"""
        print("ğŸ–¼ï¸  Generating eyecatch image...")
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
        prompt_text = self.generate_prompt_with_gemini('eyecatch.md', outline_data)
        if not prompt_text:
            return None
        
        # YAMLè¨­å®šã‚’æŠ½å‡ºã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¤‰æ›
        image_prompt = self.extract_yaml_and_convert_to_prompt(prompt_text)
        
        # OpenAI gpt-image-1ã§ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒç”»åƒç”Ÿæˆï¼ˆæ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œï¼‰
        image_data = self.generate_image_openai(image_prompt)
        if not image_data:
            return None
        
        # è‡ªå‹•åˆ†é¡ã—ã¦ä¿å­˜
        metadata = {
            'title': outline_data.get('title', ''),
            'date': outline_data.get('date', ''),
            'int_number': outline_data.get('outline_id', 'INT-01'),
            'timestamp': outline_data.get('timestamp', '')
        }
        return self.save_image(image_data, '', metadata, 'eyecatch')
    
    def generate_thumbnail(self, outline_data: Dict, chapter: str, chapter_num: int) -> Optional[str]:
        """ã‚µãƒ ãƒã‚¤ãƒ«ç”»åƒç”Ÿæˆï¼ˆImagen 3ä½¿ç”¨ã€ãƒ†ã‚­ã‚¹ãƒˆãªã—ï¼‰"""
        print(f"ğŸ–¼ï¸  Generating thumbnail for chapter {chapter_num}: {chapter[:50]}...")
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
        prompt_text = self.generate_prompt_with_gemini('thumbnail.md', outline_data, chapter)
        if not prompt_text:
            return None
        
        # YAMLè¨­å®šã‚’æŠ½å‡ºã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¤‰æ›
        image_prompt = self.extract_yaml_and_convert_to_prompt(prompt_text)
        
        # Imagen 3ã§ã‚µãƒ ãƒã‚¤ãƒ«ç”»åƒç”Ÿæˆï¼ˆãƒ†ã‚­ã‚¹ãƒˆãªã—ï¼‰
        image_data = self.generate_image_imagen(image_prompt)
        if not image_data:
            return None
        
        # è‡ªå‹•åˆ†é¡ã—ã¦ä¿å­˜
        metadata = {
            'title': outline_data.get('title', ''),
            'date': outline_data.get('date', ''),
            'int_number': outline_data.get('outline_id', 'INT-01'),
            'timestamp': outline_data.get('timestamp', '')
        }
        return self.save_image(image_data, '', metadata, 'thumbnail', chapter_num)
    
    def generate_all_images(self, outline_path: str) -> Dict:
        """å…¨ç”»åƒç”Ÿæˆ"""
        results = {
            'eyecatch': None,
            'thumbnails': [],
            'errors': []
        }
        
        # ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³èª­ã¿è¾¼ã¿
        outline_data = self.load_outline(outline_path)
        if not outline_data:
            results['errors'].append("Failed to load outline")
            return results
        
        # ç« æŠ½å‡º
        chapters = self.extract_chapters(outline_data['content'])
        print(f"ğŸ“š Found {len(chapters)} chapters")
        
        # ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒç”Ÿæˆ
        print("\n" + "="*50)
        print("EYECATCH GENERATION")
        print("="*50)
        try:
            eyecatch_path = self.generate_eyecatch(outline_data)
            results['eyecatch'] = eyecatch_path
            if eyecatch_path:
                print(f"âœ… Eyecatch completed: {eyecatch_path}")
            else:
                print("âŒ Eyecatch generation failed")
        except Exception as e:
            error_msg = f"Eyecatch generation failed: {e}"
            results['errors'].append(error_msg)
            print(f"âŒ {error_msg}")
        
        # ã‚µãƒ ãƒã‚¤ãƒ«ç”Ÿæˆ
        print("\n" + "="*50)
        print("THUMBNAIL GENERATION")
        print("="*50)
        for i, chapter in enumerate(chapters, 1):
            try:
                thumbnail_path = self.generate_thumbnail(outline_data, chapter, i)
                if thumbnail_path:
                    results['thumbnails'].append(thumbnail_path)
                    print(f"âœ… Chapter {i} completed: {thumbnail_path}")
                else:
                    print(f"âŒ Chapter {i} generation failed")
            except Exception as e:
                error_msg = f"Thumbnail {i} generation failed: {e}"
                results['errors'].append(error_msg)
                print(f"âŒ {error_msg}")
        
        return results

def main():
    parser = argparse.ArgumentParser(description='Blog Image Generator using Imagen 3')
    parser.add_argument('--outline', required=True, help='Path to outline file')
    parser.add_argument('--mode', choices=['eyecatch', 'thumbnail', 'all'], default='all', help='Generation mode')
    parser.add_argument('--chapter', type=int, help='Chapter number for thumbnail mode')
    
    args = parser.parse_args()
    
    try:
        print("ğŸš€ Blog Image Generator with Imagen 3")
        print("="*50)
        
        generator = BlogImageGenerator()
        
        if args.mode == 'all':
            results = generator.generate_all_images(args.outline)
            
            print("\n" + "="*50)
            print("GENERATION SUMMARY")
            print("="*50)
            print(f"ğŸ“Š Eyecatch: {'âœ… Success' if results['eyecatch'] else 'âŒ Failed'}")
            print(f"ğŸ“Š Thumbnails: {len(results['thumbnails'])} generated")
            
            if results['eyecatch']:
                print(f"   ğŸ“„ {results['eyecatch']}")
            
            for thumb in results['thumbnails']:
                print(f"   ğŸ“„ {thumb}")
                
            if results['errors']:
                print(f"\nâš ï¸  Errors encountered:")
                for error in results['errors']:
                    print(f"   âŒ {error}")
                    
        elif args.mode == 'eyecatch':
            outline_data = generator.load_outline(args.outline)
            if outline_data:
                path = generator.generate_eyecatch(outline_data)
                if path:
                    print(f"âœ… Eyecatch generated: {path}")
                else:
                    print("âŒ Eyecatch generation failed")
                    
        elif args.mode == 'thumbnail':
            if not args.chapter:
                print("âŒ --chapter required for thumbnail mode")
                return
            
            outline_data = generator.load_outline(args.outline)
            if outline_data:
                chapters = generator.extract_chapters(outline_data['content'])
                if args.chapter <= len(chapters):
                    chapter = chapters[args.chapter - 1]
                    path = generator.generate_thumbnail(outline_data, chapter, args.chapter)
                    if path:
                        print(f"âœ… Thumbnail generated: {path}")
                    else:
                        print("âŒ Thumbnail generation failed")
                else:
                    print(f"âŒ Chapter {args.chapter} not found (available: 1-{len(chapters)})")
                    
    except Exception as e:
        print(f"ğŸ’¥ Fatal error: {e}")
        sys.exit(1)

if __name__ == '__main__':
    main()